# -*- coding: utf-8 -*-
"""Prodigy_ML_01(Linear_Regression).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RWE4O9ZLGpTsoanzRj4rfvAmgvk9yMQa

# House Price Prediction (Prodigy Internship)

**Introduction**
 *  Hello Everyone this is my first task for Machine Learning  for Prodigy Internship
 *  In this task_01 we are going to apply Liner Regression algorithm  for predict the price from the given data

**CONTENT**

*  Data Reading
* Data Visualization
* EDA
   *  Univariate Analysis
   *  Bivariate Analysis
* Data Cleaning
* Reomve the Outliers
* Remove the Skweness
* Feature Enigineering
* Feature Transformation
    *  Encoding
* Feature Scaling
* Checking and removing multi-collineraity
* Implement the Linear Regression Algorithm
* Evaluating the model

*Installing Scikit Plot*
"""

!pip install scikit-plot

"""*Importings Libraries*"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
from sklearn.preprocessing import OrdinalEncoder,power_transform,StandardScaler,MinMaxScaler,LabelEncoder
from sklearn.model_selection import train_test_split,cross_val_score,KFold,GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
import scikitplot as skplot

"""*Data Reading*"""

data=pd.read_csv("/content/train-4.csv")
data

"""*Total Rows & Columns in my Dataset*"""

data.shape
print("Total Rows in my DataSet------->",data.shape[0])
print("Total Columns in my DataSet------->",data.shape[1])

"""*Checking Dtypes in my Dataset*"""

data.info()

"""*Statistical Details*"""

data.describe()

"""*Checking Null Values*"""

data.isna().sum().sum()

"""*Droping Unwanted Columns*"""

data.drop(["Id","Utilities"],inplace=True,axis=1)

"""*Separating the Data into Categorical & Numerical Sets*"""

data1=data.select_dtypes(include=object)
data1

col= data1.columns
print(col)
len(col)

"""**Univariate Analysis**"""

plt.figure(figsize=(22,100))
for i in range(len(col)):
  plt.subplot(15,3,i+1)
  sns.countplot(x=data1[col[i]])
  plt.title(f"CountPlot of {col[i]}",fontsize=18)
  plt.xticks(rotation=90,fontsize=18)
  plt.tight_layout()

"""***Observation***
*  From MSZoning i can say that most of the people like house that have zone Residential Low Density,Low density says people like to live in more space like villa's
*  From Street i can say that most of the people like to have home that are praved
*  From top of alley access to property i can say that most of the people like to have home at GRVL
*  From LotShape i can say mostly people like reg and very less people who like to live in IR2,IR3
* From LandContour Flatness of the property i can say that mostly people like to live near flat/Level
* From LotConfiguration i can say that mostly people like inside lot and some people like 20% of corner plot
* From LandSlope: Slope of property i can say mostly 90% of people like Gentle slope
*From Neighborhood: Physical locations within Ames city limitsi can say mostly people like to have have at North Ames after this people also like College Creek
*From Condition1: Proximity to various conditions i can say mostly people like Normal and same with condition 2
*From BldgType: Type of dwelling i can say mostly people like Single-family Detached
*From HouseStyle: Style of dwelling i can say moslty people like onestory and twostory more
*From RoofStyle: Type of roof i can say mostly people like Gable style
*From RoofMatl: Roof material i can say mostly people like clay or tile on roof
*From Exterior1st and Exterior2nd i can say moslty people like Vinyl Siding and people also like Metal Siding and hard bord
*From MasVnrType: Masonry veneer type i can say people like None
*Form exterqual and extercond i can say mostly people are happy with Average quality
*From Foundation: Type of foundation i can say moslty people like Cinder Block and Poured Contrete
*From bsmntqual and bsmtcond i can say people like Good (90-99 inches) and typical also
*From BsmtExposure: Refers to walkout or garden level walls people like No Exposure
*From BsmtFinType1: Rating of basement finished area i can say moslty people like Good Living Quarters and unfinished
*From BsmtFinType2 i can say people like good living quarters
*From CenteralAir i can say moslty people like to lave centeralair
*From Electrical: Electrical system i can say people like SBrkr	Standard Circuit Breakers & Romex
*From Countplot of Garage type i can say people love to have a home that have garage Attached to home
*From Salestype i cna say people love to have a home that have Warranty Deed - Conventional
*From salesconditon i can say people love to have a home that have normal condition  
"""

data2= data.select_dtypes(exclude=object)
data2

col1=data2.columns

plt.figure(figsize=(22,300))
for i in range(len(col1)):
  plt.subplot(100,3,i+1)
  sns.distplot(x=data2[col1[i]])
  plt.title(f"Countplot of {col1[i]}",fontsize=18)
  plt.xticks(rotation=90,fontsize=15)
  plt.tight_layout()

"""**Bivariate Analysis**

*Importig Libraries*
"""

from numpy import mean
import matplotlib.gridspec as gridspec
from matplotlib.gridspec import GridSpec

fig=plt.figure(constrained_layout=True,figsize=(20,30))
gs = GridSpec(12,3,figure=fig)

plt.subplot(gs[0,:])
ax1=sns.barplot(data=data,x="TotRmsAbvGrd",y="SalePrice",estimator = mean, palette ="flare")
plt.xlabel("TotRmsAbvGrd",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

plt.subplot(gs[1,:])
ax2=sns.barplot(data=data,x="BedroomAbvGr",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("BedroomAbvGr",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

plt.subplot(gs[2,:])
ax3= sns.barplot(data=data,x="KitchenAbvGr",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("KitchenAbvGr",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

plt.subplot(gs[3,:])
ax4 =sns.barplot(data=data,x="BsmtFullBath",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("BsmtFullBath",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

plt.subplot(gs[4,:])
ax5 =sns.barplot(data=data,x="FullBath",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("FullBath",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

plt.subplot(gs[5,:])
ax6 =sns.barplot(data=data,x="BsmtHalfBath",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("BsmtHalfBath",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

plt.subplot(gs[6,:])
ax7 =sns.barplot(data=data,x="HalfBath",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("HalfBath",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

plt.subplot(gs[7,:])
ax8 =sns.barplot(data=data,x="Fireplaces",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("Fireplaces",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

plt.subplot(gs[8,:])
ax9 =sns.barplot(data=data,x="PoolArea",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("PoolArea",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

plt.subplot(gs[9,:])
ax10 =sns.barplot(data=data,x="YrSold",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("YrSold",fontsize=18)
plt.ylabel("AverageSales_Price",fontsize=18)

plt.subplot(gs[10,:])
ax11 =sns.barplot(data=data,x="MoSold",y="SalePrice",estimator=mean,palette="flare")
plt.xlabel("Mosold",fontsize=18)
plt.ylabel("Average_SalesPrice",fontsize=18)

"""**Observation**

* Total Rooms Above Ground-As the room no. increasing the average price is also increasing till 11th room after that price start decreasing
* Bedroom ABove Ground-For the 0,4,8 Bedroom price is high and price is very less for 6 and 2
* Kitchen Above Ground-as the no of kitchen is increasing the price is reducing and mostly people take one kitchen only
* In Basement full bathrrom and half bathrooms as the bathroom size increasing the price is also increasing
* Fireplaces-As the fireplaces increasing the sale price is also increasing
* PoolArea-as big the pool the more costly the house
* YRsold-the price was high in 2006 as comapre to old year prices descresed in 2008-10
* MOSold-most of the people who sold there home in 09 month they got high price and people who sold there home on 4th month got less price

**Checking Skewness**

* -1 and -0.5, the data is negatively skewed, and if it is between 0.5 to 1, the data is positively skewed
* Right skew (also called positive skew). A right-skewed distribution is longer on the right side of its peak than on its left.
* Left skew (also called negative skew). A left-skewed distribution is longer on the left side of its peak than on its right.
* Zero skew.
"""

data2.skew()

"""**Some important points for skewness**

* Logarithmic Transformation: Apply a logarithmic function to the data. This transformation is useful when the data is positively skewed.

import numpy as np
      
transformed_data = np.log(original_data)

* Square Root Transformation: Take the square root of the data values. This transformation is suitable for reducing right skewness.


import numpy as np

transformed_data = np.sqrt(original_data)

* Box-Cox Transformation: The Box-Cox transformation is a versatile technique that can handle a range of skewness. It includes a parameter lambda (Î») that determines the type of transformation applied. This transformation requires the data to be positive.

from scipy.stats import boxcox
  
transformed_data, lambda_value = boxcox(original_data)

**Outliers**
"""

x_col = data2.columns.values
len(x_col)

plt.figure(figsize=(14,30))
for i in range(0,len(x_col)):
  plt.subplot(20,2,i+1)
  sns.boxplot(data2[x_col[i]],color="blue")
  plt.tight_layout()

"""**Co-relation between the data**"""

X_corr=data2.corr()
plt.figure(figsize=(45,75))
sns.heatmap(X_corr,annot=True)

"""**Preprocessing MissingVlaue**"""

def preprocess_missingvalue(X):
  X["LotFrontage"] = X.groupby("Neighborhood")["LotFrontage"].transform(lambda x:x.fillna(x.mean()))
  X["Electrical"] = X["Electrical"].fillna(X["Electrical"].mode()[0])
  for col in ['FireplaceQu','GarageType','GarageFinish','BsmtFinType2','PoolQC','Fence','MiscFeature','GarageQual','GarageCond','BsmtQual','BsmtCond','BsmtExposure',
                'BsmtFinType1','BsmtFinType2','MasVnrType','Alley']:
                X[col]=X[col].fillna("None")
  for col in ['GarageYrBlt','MasVnrArea']:
      X[col]=X[col].fillna(0)
  return X

"""**Feature Engineering**"""

def feature_engineering(X):
  X['SqFtPerRoom']=X['GrLivArea']/X['TotRmsAbvGrd']+(X['TotRmsAbvGrd']+
                                                    X['FullBath']+
                                                    X['HalfBath']+
                                                    X['KitchenAbvGr'])
  X['Total_Home_Quality']=X['OverallQual']+X['OverallCond']
  X['Total_Bathrooms']=(X['FullBath']+(0.5*X['HalfBath'])+
                        X['BsmtFullBath']+(0.5*X['BsmtHalfBath']))
  X['HighQualSF']=X['1stFlrSF']+X['2ndFlrSF']
  return X

"""**Removing Skewness**"""

def remove_skewness(X):
  x=X.copy()
  skew=0.5
  X_num=X.select_dtypes(exclude='object')
  skewness=X_num.apply(lambda x:x.skew())
  skewness_col=skewness[abs(skewness)>=skew].index
  X[skewness_col]=power_transform(X[skewness_col])
  X=pd.DataFrame(X,columns=x.columns)
  X = pd.get_dummies(X)
  return X

"""**Label Encoding**"""

def Encoding(X):
  le=LabelEncoder()
  colss =('MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',
       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',
       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',
       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',
       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',
       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',
       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',
       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',
       'SaleType', 'SaleCondition')

  for c in colss:
    X[c]=le.fit_transform(X[c])
  return X

"""**Removing Outliers**"""

def remove_outliers(X):

  for col in X.columns:
    X[col] = X[col].astype(float)
  for col in X.columns:
    percentile=X[col].quantile([0.01,0.98]).values
    X[col][X[col]<=percentile[0]]=percentile[0]
    X[col][X[col]>=percentile[1]]=percentile[1]

  return X

"""**Feature Scaling**"""

def Feature_Scaling(X):

  x=X.copy()
  scale=StandardScaler()
  X=scale.fit_transform(X)
  X=pd.DataFrame(X,columns=x.columns)

  return X

X = data.drop('SalePrice',axis=1)
y = data['SalePrice']

"""**Final Preprocessing**"""

def final_preprocessing(X):

  missing = preprocess_missingvalue(X)
  FE = feature_engineering(missing)
  encoding = Encoding(FE)
  skew = remove_skewness(encoding)
  scaling = Feature_Scaling(skew)

  return scaling

X=final_preprocessing(X)
X.head()

y

"""**Log Transfrom**"""

plt.figure(figsize=(16,7))
plt.subplot(1,2,1)
plt.title("Actual distribution",fontsize=15)
sns.distplot(y)
plt.subplot(1,2,2)
plt.title("Log normal transformation",fontsize=15)
sns.distplot(np.log(y))

"""**Spliting Data into test and train**"""

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X,np.log(y),test_size=0.2,random_state=42)

X_train.shape

X_test.shape

"""**Algorithm models in Dictionary sets**"""

models={
    "LinearRegression":LinearRegression()
}

models.keys()

CVS = []
R2 = []
MSE = []
MAE = []
RMSE = []
NAME = []
kf  =  KFold(n_splits = 5,shuffle = True)
for name, model in models.items():
  print("************************************************",name,"*****************************************************")
  NAME.append(name)
  model.fit(X_train,y_train)
  y_pred = model.predict(X_test)
  mse = mean_squared_error(y_test,y_pred)
  MSE.append(mse)
  print("MEAN SQUARED ERROR",mse)
  mae = mean_absolute_error(y_test,y_pred)
  MAE.append(mae)
  print('\n')
  print("MEAN ABSOLUTE ERROR",mae)
  cvs = cross_val_score(model,X,np.log(y),scoring = 'r2',cv = kf).mean()
  CVS.append(cvs)
  print('\n')
  print("CVS_SCORE",cvs)
  r2 = r2_score(y_test,y_pred)
  R2.append(r2)
  print('\n')
  print("R2_SCORE",r2)
  rmse = np.sqrt(mse)
  RMSE.append(rmse)
  print('\n')
  print("RMSE",rmse)
  print('\n')
  print('MODEL PERFORMANCE CURVE')
  skplot.estimators.plot_learning_curve(model,X,np.log(y),cv = kf,scoring = 'r2',title = name,text_fontsize = 'large')
  plt.show()

models_result=pd.DataFrame({
    "NAME":NAME,
    "Cross_Val_Score":CVS,
    "R2_score":R2,
    "Mean_squared_error":MSE,
    "Mean_Absolute_Error":MAE,
    "RMSE":RMSE
})

models_result

test = pd.read_csv("/content/train-4.csv")

test

test = final_preprocessing(test)

test